{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word Probabilities.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Td7lD2FWSKUH"},"source":["# Importing Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYmYwP3phBt3","executionInfo":{"status":"ok","timestamp":1607299392761,"user_tz":300,"elapsed":5935,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"6d96ea20-27a5-4f60-c5d9-9ca4dabaa8cd"},"source":["!pip install langdetect\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (1.0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9dZVr2r6SBFt","executionInfo":{"status":"ok","timestamp":1607299395529,"user_tz":300,"elapsed":8681,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"ad88074d-af73-40ab-c9f8-e82e44971e10"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","from nltk import sent_tokenize, word_tokenize\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import re  \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","\n","import langdetect\n","from langdetect import detect # language detection"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9oE0C3um_fny"},"source":["# Reading Data"]},{"cell_type":"code","metadata":{"id":"yG3NGHqg_oM4"},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from pydrive.drive import GoogleDrive\n","from pydrive.auth import GoogleAuth\n","from oauth2client.client import GoogleCredentials\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"799zWqZMD0AO"},"source":["link = 'https://drive.google.com/file/d/1v9xL-cWgvly83FwpNYoqY6k3LlLbA38Y/view?usp=sharing' # The shareable link\n","  \n","# to get the id part of the file \n","id = link.split(\"/\")[-2]\n","\n","myfile = drive.CreateFile({'id':id})\n","myfile.GetContentFile('clean_data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"XFfAe0AqKpHU","executionInfo":{"status":"ok","timestamp":1607299411771,"user_tz":300,"elapsed":21126,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"3e237a39-d260-457e-9fc8-660cb913a135"},"source":["df_model = pd.read_csv('clean_data.csv', index_col=0)\n","df_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ended</th>\n","      <th>length</th>\n","      <th>type</th>\n","      <th>label</th>\n","      <th>tidy_text</th>\n","      <th>token_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>47018</td>\n","      <td>True</td>\n","      <td>102</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>The overarching quality the Bloomberg era was ...</td>\n","      <td>['The', 'overarching', 'quality', 'Bloomberg',...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>94338</td>\n","      <td>True</td>\n","      <td>142</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>This about bad morning commute gets all winter...</td>\n","      <td>['This', 'bad', 'morning', 'commute', 'gets', ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>44507</td>\n","      <td>True</td>\n","      <td>631</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>More Saskatchewan Liquor Privatization latest ...</td>\n","      <td>['More', 'Saskatchewan', 'Liquor', 'Privatizat...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>163493</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Killen was here Patrick Killen helped define t...</td>\n","      <td>['Killen', 'Patrick', 'Killen', 'helped', 'def...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>91925</td>\n","      <td>True</td>\n","      <td>51</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Mailbox Rental Mail Forwarding Services Delawa...</td>\n","      <td>['Mailbox', 'Rental', 'Mail', 'Forwarding', 'S...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>88658</td>\n","      <td>True</td>\n","      <td>548</td>\n","      <td>train</td>\n","      <td>GPT-2</td>\n","      <td>The official website for Donten Warau Maken an...</td>\n","      <td>['The', 'official', 'website', 'Donten', 'Wara...</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>7575</td>\n","      <td>True</td>\n","      <td>803</td>\n","      <td>train</td>\n","      <td>GPT-2</td>\n","      <td>have long slow and somewhat unproductive relat...</td>\n","      <td>['long', 'slow', 'somewhat', 'unproductive', '...</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>38428</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>GPT-2</td>\n","      <td>Flexibility Not Option The Nourish School use ...</td>\n","      <td>['Flexibility', 'Not', 'Option', 'The', 'Nouri...</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>129005</td>\n","      <td>True</td>\n","      <td>137</td>\n","      <td>train</td>\n","      <td>GPT-2</td>\n","      <td>Duck Dynasty Phil Robertson will have make due...</td>\n","      <td>['Duck', 'Dynasty', 'Phil', 'Robertson', 'make...</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>84470</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>GPT-2</td>\n","      <td>The last time wrote length about the political...</td>\n","      <td>['The', 'last', 'time', 'wrote', 'length', 'po...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100000 rows × 7 columns</p>\n","</div>"],"text/plain":["           id  ...                                        token_words\n","0       47018  ...  ['The', 'overarching', 'quality', 'Bloomberg',...\n","1       94338  ...  ['This', 'bad', 'morning', 'commute', 'gets', ...\n","2       44507  ...  ['More', 'Saskatchewan', 'Liquor', 'Privatizat...\n","3      163493  ...  ['Killen', 'Patrick', 'Killen', 'helped', 'def...\n","4       91925  ...  ['Mailbox', 'Rental', 'Mail', 'Forwarding', 'S...\n","...       ...  ...                                                ...\n","99995   88658  ...  ['The', 'official', 'website', 'Donten', 'Wara...\n","99996    7575  ...  ['long', 'slow', 'somewhat', 'unproductive', '...\n","99997   38428  ...  ['Flexibility', 'Not', 'Option', 'The', 'Nouri...\n","99998  129005  ...  ['Duck', 'Dynasty', 'Phil', 'Robertson', 'make...\n","99999   84470  ...  ['The', 'last', 'time', 'wrote', 'length', 'po...\n","\n","[100000 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7tPLx7k9sGdC","executionInfo":{"status":"ok","timestamp":1607298416096,"user_tz":300,"elapsed":24404,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"7a7b6333-9470-45fb-ad8d-1744943ce4e3"},"source":["type(df_model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.frame.DataFrame"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"WUiC0jivyQYX"},"source":["# Word Probabilities"]},{"cell_type":"markdown","metadata":{"id":"m-LO1DRG2fjt"},"source":["## GLTR"]},{"cell_type":"markdown","metadata":{"id":"qEvZ0k0o5Tc-"},"source":["http://gltr.io/dist/index.html\n","\n","https://github.com/HendrikStrobelt/detecting-fake-text\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-Pq-P023UuK","executionInfo":{"status":"ok","timestamp":1607298535630,"user_tz":300,"elapsed":486,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"58d2a740-646b-4665-b6ab-4c95cb13604a"},"source":["!git clone https://github.com/HendrikStrobelt/detecting-fake-text.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'detecting-fake-text' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31QLmGD_4F_Z","executionInfo":{"status":"ok","timestamp":1607299424504,"user_tz":300,"elapsed":2755,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"9b38717b-5e58-4a28-aade-09555f53bff8"},"source":["%cd /content/detecting-fake-text\n","!pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/detecting-fake-text\n","Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.6.2)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.5)\n","Requirement already satisfied: connexion[swagger-ui] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.7.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.1.2)\n","Requirement already satisfied: PyYaml in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.13)\n","Requirement already satisfied: flask_cors in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.0.9)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (1.16.30)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (4.41.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->-r requirements.txt (line 2)) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->-r requirements.txt (line 2)) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->-r requirements.txt (line 2)) (0.8)\n","Requirement already satisfied: jsonschema>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from connexion[swagger-ui]->-r requirements.txt (line 4)) (2.6.0)\n","Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from connexion[swagger-ui]->-r requirements.txt (line 4)) (0.5.1)\n","Requirement already satisfied: clickclick>=1.2 in /usr/local/lib/python3.6/dist-packages (from connexion[swagger-ui]->-r requirements.txt (line 4)) (20.10.2)\n","Requirement already satisfied: openapi-spec-validator>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from connexion[swagger-ui]->-r requirements.txt (line 4)) (0.2.9)\n","Requirement already satisfied: swagger-ui-bundle>=0.0.2; extra == \"swagger-ui\" in /usr/local/lib/python3.6/dist-packages (from connexion[swagger-ui]->-r requirements.txt (line 4)) (0.0.8)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->-r requirements.txt (line 5)) (1.0.1)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->-r requirements.txt (line 5)) (2.11.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->-r requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from flask_cors->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (0.3.3)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.30 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (1.19.30)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->-r requirements.txt (line 5)) (1.1.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.30->boto3->pytorch-pretrained-bert>=0.6.1->-r requirements.txt (line 1)) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wqogS6h22pDn"},"source":["import numpy as np\n","import torch\n","import time\n","import nltk\n","\n","from pytorch_pretrained_bert import (GPT2LMHeadModel, GPT2Tokenizer,\n","                                     BertTokenizer, BertForMaskedLM)\n","\n","from matplotlib import pyplot as plt\n","\n","class AbstractLanguageChecker():\n","    \"\"\"\n","    Abstract Class that defines the Backend API of GLTR.\n","\n","    To extend the GLTR interface, you need to inherit this and\n","    fill in the defined functions.\n","    \"\"\"\n","\n","    def __init__(self):\n","        '''\n","        In the subclass, you need to load all necessary components\n","        for the other functions.\n","        Typically, this will comprise a tokenizer and a model.\n","        '''\n","        self.device = torch.device(\n","            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def check_probabilities(self, in_text, topk=40):\n","        '''\n","        Function that GLTR interacts with to check the probabilities of words\n","\n","        Params:\n","        - in_text: str -- The text that you want to check\n","        - topk: int -- Your desired truncation of the head of the distribution\n","\n","        Output:\n","        - payload: dict -- The wrapper for results in this function, described below\n","\n","        Payload values\n","        ==============\n","        bpe_strings: list of str -- Each individual token in the text\n","        real_topk: list of tuples -- (ranking, prob) of each token\n","        pred_topk: list of list of tuple -- (word, prob) for all topk\n","        '''\n","        raise NotImplementedError\n","\n","    def postprocess(self, token):\n","        \"\"\"\n","        clean up the tokens from any special chars and encode\n","        leading space by UTF-8 code '\\u0120', linebreak with UTF-8 code 266 '\\u010A'\n","        :param token:  str -- raw token text\n","        :return: str -- cleaned and re-encoded token text\n","        \"\"\"\n","        raise NotImplementedError\n","\n","\n","def top_k_logits(logits, k):\n","    '''\n","    Filters logits to only the top k choices\n","    from https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n","    '''\n","    if k == 0:\n","        return logits\n","    values, _ = torch.topk(logits, k)\n","    min_values = values[:, -1]\n","    return torch.where(logits < min_values,\n","                       torch.ones_like(logits, dtype=logits.dtype) * -1e10,\n","                       logits)\n","\n","\n","\n","class LM(AbstractLanguageChecker):\n","    def __init__(self, model_name_or_path=\"gpt2\"):\n","        super(LM, self).__init__()\n","        self.enc = GPT2Tokenizer.from_pretrained(model_name_or_path)\n","        self.model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n","        self.model.to(self.device)\n","        self.model.eval()\n","        self.start_token = '<|endoftext|>'\n","        # print(\"Loaded GPT-2 model!\")\n","\n","    def check_probabilities(self, in_text, topk=40):\n","        # Process input\n","        start_t = torch.full((1, 1),\n","                             self.enc.encoder[self.start_token],\n","                             device=self.device,\n","                             dtype=torch.long)\n","        context = self.enc.encode(in_text)\n","        context = torch.tensor(context,\n","                               device=self.device,\n","                               dtype=torch.long).unsqueeze(0)\n","        context = torch.cat([start_t, context], dim=1)\n","        # Forward through the model\n","        logits, _ = self.model(context)\n","\n","        # construct target and pred\n","        yhat = torch.softmax(logits[0, :-1], dim=-1)\n","        y = context[0, 1:]\n","        # Sort the predictions for each timestep\n","        sorted_preds = np.argsort(-yhat.data.cpu().numpy())\n","        # [(pos, prob), ...]\n","        real_topk_pos = list(\n","            [int(np.where(sorted_preds[i] == y[i].item())[0][0])\n","             for i in range(y.shape[0])])\n","        real_topk_probs = yhat[np.arange(\n","            0, y.shape[0], 1), y].data.cpu().numpy().tolist()\n","        real_topk_probs = list(map(lambda x: round(x, 5), real_topk_probs))\n","\n","        real_topk = list(zip(real_topk_pos, real_topk_probs))\n","        # [str, str, ...]\n","        bpe_strings = [self.enc.decoder[s.item()] for s in context[0]]\n","\n","        bpe_strings = [self.postprocess(s) for s in bpe_strings]\n","\n","        # [[(pos, prob), ...], [(pos, prob), ..], ...]\n","        pred_topk = [\n","            list(zip([self.enc.decoder[p] for p in sorted_preds[i][:topk]],\n","                     list(map(lambda x: round(x, 5),\n","                              yhat[i][sorted_preds[i][\n","                                      :topk]].data.cpu().numpy().tolist()))))\n","            for i in range(y.shape[0])]\n","\n","        pred_topk = [[(self.postprocess(t[0]), t[1]) for t in pred] for pred in pred_topk]\n","        payload = {'bpe_strings': bpe_strings,\n","                   'real_topk': real_topk,\n","                   'pred_topk': pred_topk}\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","\n","        return payload\n","\n","    def sample_unconditional(self, length=100, topk=5, temperature=1.0):\n","        '''\n","        Sample `length` words from the model.\n","        Code strongly inspired by\n","        https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n","\n","        '''\n","        context = torch.full((1, 1),\n","                             self.enc.encoder[self.start_token],\n","                             device=self.device,\n","                             dtype=torch.long)\n","        prev = context\n","        output = context\n","        past = None\n","        # Forward through the model\n","        with torch.no_grad():\n","            for i in range(length):\n","                logits, past = self.model(prev, past=past)\n","                logits = logits[:, -1, :] / temperature\n","                # Filter predictions to topk and softmax\n","                probs = torch.softmax(top_k_logits(logits, k=topk),\n","                                      dim=-1)\n","                # Sample\n","                prev = torch.multinomial(probs, num_samples=1)\n","                # Construct output\n","                output = torch.cat((output, prev), dim=1)\n","\n","        output_text = self.enc.decode(output[0].tolist())\n","        return output_text\n","\n","    def postprocess(self, token):\n","        with_space = False\n","        with_break = False\n","        if token.startswith('Ġ'):\n","            with_space = True\n","            token = token[1:]\n","            # print(token)\n","        elif token.startswith('â'):\n","            token = ' '\n","        elif token.startswith('Ċ'):\n","            token = ' '\n","            with_break = True\n","\n","        token = '-' if token.startswith('â') else token\n","        token = '“' if token.startswith('ľ') else token\n","        token = '”' if token.startswith('Ŀ') else token\n","        token = \"'\" if token.startswith('Ļ') else token\n","\n","        if with_space:\n","            token = '\\u0120' + token\n","        if with_break:\n","            token = '\\u010A' + token\n","\n","        return token"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alfUzZZ870HV"},"source":["from statistics import mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0rZA1hf4r8O"},"source":["def plot_text(vals, what, name):\n","    if what==\"prob\":\n","        ourvals = vals[0]\n","        x = list(range(1,len(ourvals)+1))\n","        y = ourvals\n","        plt.plot(x, y, color='orange')\n","        plt.ylim(0,1)\n","        plt.savefig(name + \".png\")\n","        # plt.show()\n","    elif what==\"rank\":\n","        ourvals = vals[1]\n","        x = list(range(1, len(ourvals) + 1))\n","        y = ourvals\n","        plt.plot(x, y, color='orange')\n","        plt.ylim(-1000, 50000)\n","        plt.savefig(name + \".png\")\n","        # plt.show()\n","def main_code(raw_text):\n","\n","    lm = LM()\n","    # start = time.time()\n","    payload = lm.check_probabilities(raw_text, topk=5)\n","    # print(payload[\"pred_topk\"])\n","    real_topK = payload[\"real_topk\"]\n","    ranks = [i[0] for i in real_topK]\n","    preds = [i[1] for i in real_topK]\n","    # print(mean(ranks))\n","    # print(mean(preds))\n","    # plot_text([preds, ranks], 'rank', \"rank_\")\n","    # end = time.time()\n","    # print(\"{:.2f} Seconds for a check with GPT-2\".format(end - start))\n","    return mean(preds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHTSHX0e5w3B","executionInfo":{"status":"ok","timestamp":1607299533250,"user_tz":300,"elapsed":5497,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"9f91bd7e-0bd2-448b-f45e-fc83e3bbd123"},"source":["main_code(df_model['tidy_text'][75000])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.16807669404517453"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"rNlEbqyKW8bY","executionInfo":{"status":"ok","timestamp":1607299574910,"user_tz":300,"elapsed":555,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"c56ca1f3-434c-47ff-f137-a476fbeb40f3"},"source":["test = df_model[:500]\n","test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ended</th>\n","      <th>length</th>\n","      <th>type</th>\n","      <th>label</th>\n","      <th>tidy_text</th>\n","      <th>token_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>47018</td>\n","      <td>True</td>\n","      <td>102</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>The overarching quality the Bloomberg era was ...</td>\n","      <td>['The', 'overarching', 'quality', 'Bloomberg',...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>94338</td>\n","      <td>True</td>\n","      <td>142</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>This about bad morning commute gets all winter...</td>\n","      <td>['This', 'bad', 'morning', 'commute', 'gets', ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>44507</td>\n","      <td>True</td>\n","      <td>631</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>More Saskatchewan Liquor Privatization latest ...</td>\n","      <td>['More', 'Saskatchewan', 'Liquor', 'Privatizat...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>163493</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Killen was here Patrick Killen helped define t...</td>\n","      <td>['Killen', 'Patrick', 'Killen', 'helped', 'def...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>91925</td>\n","      <td>True</td>\n","      <td>51</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Mailbox Rental Mail Forwarding Services Delawa...</td>\n","      <td>['Mailbox', 'Rental', 'Mail', 'Forwarding', 'S...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>73877</td>\n","      <td>True</td>\n","      <td>659</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Old baseball equipment file photo Photo Jupite...</td>\n","      <td>['Old', 'baseball', 'equipment', 'file', 'phot...</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>124016</td>\n","      <td>True</td>\n","      <td>422</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Filming the untitled fourth Avengers film curr...</td>\n","      <td>['Filming', 'untitled', 'fourth', 'Avengers', ...</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>108272</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Frank Tanana Careeer Stats What does this mean...</td>\n","      <td>['Frank', 'Tanana', 'Careeer', 'Stats', 'What'...</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>117827</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>Turns out wonky website and warp speed policy ...</td>\n","      <td>['Turns', 'wonky', 'website', 'warp', 'speed',...</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>120514</td>\n","      <td>False</td>\n","      <td>1024</td>\n","      <td>train</td>\n","      <td>real</td>\n","      <td>This not profile Hillary Clinton not review he...</td>\n","      <td>['This', 'profile', 'Hillary', 'Clinton', 'rev...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 7 columns</p>\n","</div>"],"text/plain":["         id  ...                                        token_words\n","0     47018  ...  ['The', 'overarching', 'quality', 'Bloomberg',...\n","1     94338  ...  ['This', 'bad', 'morning', 'commute', 'gets', ...\n","2     44507  ...  ['More', 'Saskatchewan', 'Liquor', 'Privatizat...\n","3    163493  ...  ['Killen', 'Patrick', 'Killen', 'helped', 'def...\n","4     91925  ...  ['Mailbox', 'Rental', 'Mail', 'Forwarding', 'S...\n","..      ...  ...                                                ...\n","495   73877  ...  ['Old', 'baseball', 'equipment', 'file', 'phot...\n","496  124016  ...  ['Filming', 'untitled', 'fourth', 'Avengers', ...\n","497  108272  ...  ['Frank', 'Tanana', 'Careeer', 'Stats', 'What'...\n","498  117827  ...  ['Turns', 'wonky', 'website', 'warp', 'speed',...\n","499  120514  ...  ['This', 'profile', 'Hillary', 'Clinton', 'rev...\n","\n","[500 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFT1uudJuGr7","executionInfo":{"status":"ok","timestamp":1607302202069,"user_tz":300,"elapsed":2619826,"user":{"displayName":"minh-tuan Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggub3dmJN2o2jLELkL53mJM1kb5QHrOPJZX-1Hm=s64","userId":"09733443394546313236"}},"outputId":"7542120e-718c-46e6-d695-2e0bd7efa789"},"source":["pred = test.apply(lambda row: main_code(row['tidy_text']), axis=1)\n","pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      0.029103\n","1      0.062097\n","2      0.080715\n","3      0.103187\n","4      0.082092\n","         ...   \n","495    0.099868\n","496    0.235695\n","497    0.150966\n","498    0.106068\n","499    0.080466\n","Length: 500, dtype: float64"]},"metadata":{"tags":[]},"execution_count":15}]}]}